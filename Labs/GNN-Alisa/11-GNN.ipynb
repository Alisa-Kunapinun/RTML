{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: GNNs (Graph Neural Networks)\n",
    "\n",
    "In this lab, we will develop Graph Neural Networks (GNN).\n",
    "\n",
    "Reference:\n",
    "- [Graph Neural Networks: A review of methods and applications](arxiv.org/ftp/arxiv/papers/1812/1812.08434.pdf)\n",
    "- [A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)](https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3)\n",
    "- [Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric](towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8)\n",
    "- [Graph Neural Network (GNN): What It Is and How to Use It](https://builtin.com/data-science/gnn)\n",
    "- [An Introduction to Graph Neural Network(GNN) For Analysing Structured Data](https://towardsdatascience.com/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is GNNs?\n",
    "\n",
    "Graph Neural Network(GNN) is the first introduce in 2009, [cite](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf). GNN is a neural model that can be applied directly to graphs without prior knowledge of each component. GNN provides a convenient method for performing node, edge, and graph level prediction tasks.\n",
    "\n",
    "GNN recently has received a lot of attention because its ability to analyze graph structural data which models a set of objects and their relationships.\n",
    "\n",
    "In order to incorporate graph structured information in the data processing step, the underlying graph structured data is encoded using the topological relationships between the nodes of the graph. This class of techniques includes recursive neural networks and Markov chains, which are commonly used to solve graph and node-focused problems.\n",
    "\n",
    "## Graph Theory\n",
    "\n",
    "A graph is a data structure made up of two parts: **vertices ($V$)** and **edges ($E$)**. It is a mathematical structure that is used to examine the pair-wise relationship between objects and entities.\n",
    "\n",
    "A graph ($G$) is defined as\n",
    "$$G=(V,E)$$\n",
    "where\n",
    "- $V$ is a set of nodes or vertices. These two terms are interchangeable.\n",
    "- $E$ is the edges between them. Edges can be either directed or undirected, depending on whether there exist directional dependencies between vertices.\n",
    "\n",
    "<img src=\"img/GNNSimpleGraph.webp\" title=\"A simple Graph\" style=\"width: 150px;\" />\n",
    "\n",
    "A graph is often represented by an Adjacency matrix ($A$). If a graph has $N$ nodes, then $A$ has a dimension of ($N\\times N$). Mathematically, the graph’s adjacency matrix has a value of 1 only when there is an edge; otherwise it’s zero.\n",
    "\n",
    "<img src=\"img/AdjacencyMatrix.PNG\" title=\"Adjacency matrix\" style=\"width: 600px;\" />\n",
    "\n",
    "Another **feature matrix** is sometimes provided to describe the nodes in the graph. If each node has $F$ features, then the dimension of the feature matrix $X$ is ($N \\times F$).\n",
    "\n",
    "<img src=\"img/FeatureMatrix.PNG\" title=\"Feature matrix\" style=\"width: 600px;\" />\n",
    "\n",
    "We can perform $A\\times X$. This turns the matrix multiplication, $H$ into the summation of nodes connected to the reference node.\n",
    "\n",
    "<img src=\"img/multiMatrix.PNG\" title=\"Summation matrix\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph concept, why so difficult?\n",
    "\n",
    "1. A graph does not exist in Euclidean space, so it cannot be represented by any of the coordinate systems we are familiar with. This makes graph data much more difficult to interpret when compared to other types of data such as waves, images, or time-series signals, all of which can be mapped to a 2-D or 3-D space.\n",
    "2. Graphs do not have a fixed shape. Consider the following example. Graphs A and B have completely different structures and appear completely different from one another, but when converted to adjacency matrix representation, the two graphs have the same adjacency matrix (if we ignore the weight of the edges).\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/GraphA.webp\" title=\"A\" style=\"width: 150px;\" /> </td>\n",
    "<td> <img src=\"img/GraphB.webp\" title=\"B\" style=\"width: 150px;\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "3. In general, graphs are difficult to visualize for human interpretation. This is not about small graphs, but about massive graphs with hundreds or thousands of nodes. Humans struggle to understand the graph when the dimension is very high and the nodes are densely grouped. As a result, training a machine for this task is difficult.\n",
    "\n",
    "<img src=\"img/circuitnetlist.webp\" title=\"B\" style=\"width: 300px;\" />\n",
    "\n",
    "## Advantages of Graphs\n",
    "\n",
    "The graphs have been used for a variety of reasons as:\n",
    "\n",
    "1. Graphs are a better way to represent abstract concepts such as relationships and interactions. They also provide a visually intuitive approach to thinking about these concepts. Graphs are also a natural starting point for analyzing relationships in a social context.\n",
    "2. Graphs can solve more complex problems by reducing them to simpler representations or by transforming them into representations from various perspectives.\n",
    "3. Graph theories and concepts are used to investigate and model Social Networks, Fraud patterns, Power consumption patterns, Virality, and Influence in Social Media. The most well-known application of Graph Theory for Data Science is probably Social Network Analysis (SNA).\n",
    "\n",
    "## Traditional graph analysis methods\n",
    "\n",
    "1. Searching algorithms, e.g. Breadth First Search (BFS), Dept First Search (DFS)\n",
    "2. Shortest path algorithms, e.g. Dijkstra’s algorithm, Nearest Neighbour\n",
    "3. Spanning-tree algorithms, e.g. Prim’s algorithm\n",
    "4. clustering methods, e.g. Highly Connected Components, k-mean\n",
    "\n",
    "The limitation of such algorithms is that we must first gain confidence in the graph before we can apply the algorithm. It does not allow us to investigate the graph itself. Most importantly, graph level classification is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Network\n",
    "\n",
    "A Graph Neural Network is a type of Neural Network that operates directly on the Graph structure. Node classification is a common application of GNN. Essentially, each node in the graph has a label, and we want to predict the labels of the nodes without using ground truth.\n",
    "\n",
    "There are mainly three types of graph neural networks in the literature:\n",
    "\n",
    "1. Recurrent Graph Neural Network\n",
    "2. Spatial Convolutional Network\n",
    "3. Spectral Convolutional Network\n",
    "\n",
    "### GNN function\n",
    "\n",
    "Each node $v$ in the node classification problem is identified by its feature $x_v$ and associated with a ground-truth label $t_v$. The goal is to use the labeled nodes in a partially labeled graph $G$ to predict the labels of the unlabeled nodes. It learns to represent each node with a d-dimensional vector (state) $h_v$ containing information about its surroundings. Specifically,\n",
    "\n",
    "$$h_v=f(x_v,x_{co[v]},h_{ne[v]},x_{ne[v]})$$\n",
    "\n",
    "where $x_{co[v]}$ refers to the features of the edges connecting with $v$, $h_{ne[v]}$ refers to the embedding of $v$'s neighboring nodes, and $x_{ne[v]}$ refers to the features of $v$'s neighboring nodes. The transition function $f$ is responsible for projecting these inputs onto a d-dimensional space.\n",
    "\n",
    "We can use the Banach fixed point theorem to rewrite the above equation as an iteratively updated process because we are looking for a unique solution for $h_v$. This operation is also known as message passing or neighborhood aggregation.\n",
    "\n",
    "$$H^{t+1}=F(H^t,X)$$\n",
    "\n",
    "$H$ and $X$ denote the concatenation of all the $h$ and $x$, respectively.\n",
    "\n",
    "### Output\n",
    "\n",
    "The output of the GNN is computed by passing the state $h_v$ as well as the feature $x_v$ to an output function $g$.\n",
    "\n",
    "$$o_v=g(h_v,x_v)$$\n",
    "\n",
    "Both $f$ and $g$ here can be interpreted as feed-forward fully-connected Neural Networks. \n",
    "\n",
    "### Loss function\n",
    "\n",
    "The L1 loss can be straightforwardly formulated as the following:\n",
    "\n",
    "$$\\mathcal{L}_1=\\sum_{i=1}^p(t_i-o_i)$$\n",
    "\n",
    "which can be optimized via gradient descent.\n",
    "\n",
    "### Original GNN limitation\n",
    "There are three main limitations:\n",
    "\n",
    "1. If the assumption of \"fixed point\" is relaxed, Multi-layer Perceptron can be used to learn a more stable representation while eliminating the iterative update process. This is because different iterations of the original proposal use the same parameters of the transition function f, whereas different parameters in different layers of MLP allow for hierarchical feature extraction.\n",
    "2. It cannot process edge information (for example, different edges in a knowledge graph may indicate different relationships between nodes).\n",
    "3. Fixed point can discourage node distribution diversification and thus may be unsuitable for learning to represent nodes.\n",
    "\n",
    "Several GNN variants have been proposed to address the aforementioned issue. However, they are not covered as they are not the focus in this post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepWalk\n",
    "\n",
    "Reference: http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\n",
    "\n",
    "DeepWalk is the first algorithm to propose unsupervised node embedding learning. In terms of training, it is very similar to word embedding. The motivation is that the distribution of nodes in a graph and words in a corpus follows a power law, as illustrated in the figure below:\n",
    "\n",
    "<img src=\"img/deepwalk.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "The algorithm contains two steps:\n",
    "\n",
    "1. Perform random walks on nodes in a graph to generate node sequences\n",
    "2. Run skip-gram to learn the embedding of each node based on the node sequences generated in step 1\n",
    "\n",
    "At each time step of the random walk, the next node is sampled uniformly from the neighbor of the previous node. Each sequence is then truncated into sub-sequences of length $2|w| + 1$, where w denotes the window size in skip-gram.\n",
    "\n",
    "You can learn more about skip-gram in the [link](https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c)\n",
    "\n",
    "Hierarchical softmax is applied to address the costly computation of softmax due to the huge number of nodes. To compute the softmax value of each of the individual output element, we must compute all the $e^{x_k}$ for all the element $k$.\n",
    "\n",
    "$$softmax(x)_i = \\frac{e^{x_i}}{\\sum_{k=1}^K e^{x_k}}$$\n",
    "\n",
    "Therefore, the computation time is $O(|V|)$ for the original softmax, where $V$ denotes the set of vertices in the graph.\n",
    "\n",
    "To solve the problem, hierarchical softmax employs a binary tree. All of the leaves $(v1, v2, \\dots)$ are vertices in this binary tree. Each inner node contains a binary classifier that determines which path to take. To compute the probability of a given vertex $v_k$, simply add the probabilities of each sub-path from the root node to the leave $v_k$. Because the probability of each node's children sums to one, the property that the sum of the probability of all vertices equals one remains valid in the hierarchical softmax. As the longest path for an element, the computation time is now reduced to $O(\\log|V|)$.\n",
    "\n",
    "<img src=\"img/HierarchicalSoftmax.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "After training a DeepWalk GNN, the model has learned a good representation of each node, as shown in the figure below. In the input graph, different colors represent different labels. We can see in the output graph (embedding with two dimensions) that nodes with the same labels are clustered together, whereas most nodes with different labels are properly separated.\n",
    "\n",
    "<img src=\"img/Deepwalkresult.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "The main problem with DeepWalk is that it lacks generalization ability. When a new node is added, the model must be re-trained to represent this node (transductive). As a result, such GNN is unsuitable for dynamic graphs with constantly changing nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage\n",
    "\n",
    "Reference: https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf\n",
    "\n",
    "GraphSage provides a solution to the aforementioned problem by inductively learning the embedding for each node. In particular, each node is represented by the sum of its neighbors. As a result, even if a previously unseen node appears in the graph during training, it can still be properly represented by its neighbors.\n",
    "\n",
    "<img src=\"img/GraphSageAlgo.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "The number of update iterations is indicated by the outer loop, and $h^k_v$ is the latent vector of node $v$ at update iteration $k$. $h^k_v$ is updated at each update iteration using an aggregation function, the latent vectors of $v$ and $v$'s neighborhood from the previous iteration, and a weight matrix $W^k$. There are three aggregation functions as:\n",
    "\n",
    "1. **Mean aggregator**: takes the average of the latent vectors of a node and all its neighborhood.\n",
    "\n",
    "$$h_v^k\\leftarrow \\sigma(W\\cdot \\text{MEAN}(\\{h_v^{k-1}\\}\\cup \\{h_u^{k-1},\\forall u \\in \\mathcal{N}(v)\\}))$$\n",
    "\n",
    "Compared with the original equation, it removes the concatenation operation at line 5 in the above pseudo code. This operation can be viewed as a “skip-connection”, which later in the paper proved to largely improve the performance of the model.\n",
    "\n",
    "2. **LSTM aggregator**: Since the nodes in the graph don’t have any order, they assign the order randomly by permuting these nodes.\n",
    "\n",
    "3. **Pooling aggregator**: This operator performs an element-wise pooling function on the neighboring set. Below shows an example of max-pooling:\n",
    "\n",
    "$$\\text{AGGREGATE}_k^{pool}= \\max(\\{\\sigma(W_{pool}h_{u_i}^k+b),\\forall u_i \\in \\mathcal{N}(v)\\})$$\n",
    "\n",
    "which can be substituted for mean-pooling or any other symmetric pooling function. It is stated that the pooling aggregator performs the best, while the mean-pooling and max-pooling aggregators perform similarly. The paper's default aggregation function is max-pooling.\n",
    "\n",
    "### Loss function\n",
    "\n",
    "The loss function is defined as the following:\n",
    "\n",
    "$$J_{\\mathcal{G}}(z_u)=-\\log(\\sigma(z_u^\\top))-Q\\cdot \\mathbb{E}_{v_n\\sim P_n(v)}\\log(\\sigma(-z_u^\\top z_{v_n}))$$\n",
    "\n",
    "where $u$ and $v$ co-occur in a fixed-length random walk, while $v_n$ are the negative samples that don’t co-occur with $u$. Such loss function encourages nodes closer to have similar embedding, while those far apart to be separated in the projected space. Via this approach, the nodes will gain more and more information about their neighborhoods.\n",
    "\n",
    "By aggregating its nearby nodes, GraphSage generates representable embedding for unseen nodes. It enables the application of node embedding to domains involving dynamic graphs, where the structure of the graph is constantly changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECURRENT GRAPH NEURAL NETWORK\n",
    "\n",
    "RecGNN is built with an assumption of Banach Fixed-Point Theorem. Banach Fixed-Point Theorem states:\n",
    "\n",
    "***Let $(X,d)$ be a complete metric space and let $(T:X\\rightarrow X)$ be a contraction mapping. Then $T$ has a unique fixed point $(x*)$ and for any $x\\in X$ the sequence $T_n(x)$ for $n \\rightarrow \\infty$ converges to $(x*)$.***\n",
    "\n",
    "If apply the mapping $T$ on $x$ for $k$ times, $x^k$ should be almost equal to $x^{(k-1)}$.\n",
    "\n",
    "$$x^k=T(x^{k-1}),k\\in (1,n)$$\n",
    "\n",
    "RecGNN defines a parameterized function $f_w$:\n",
    "\n",
    "$$x_n=f_w(l_n,l_{co[n]},x_{ne[n]},l_{ne[n]})$$\n",
    "\n",
    "$l_n$, $l_{co}$, $x_{ne}$, $l_{ne}$ represent the features of the current node $[n]$, the edges of the node $[n]$, the state of the neighboring nodes, and the features of the neighboring nodes.\n",
    "\n",
    "<img src=\"img/7_gnn.png\" title=\"The Graph Neural Network Model paper\" style=\"width: 500px;\" />\n",
    "\n",
    "Finally, after $k$ iterations, the graph neural network model makes use of the final node state to produce an output in order to make a decision about each node. The output function is defined as:\n",
    "\n",
    "$$o_n=g_w(x_n,l_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Convolution network\n",
    "\n",
    "The spatial convolution network is similar to the convolution neural networks (CNN) that dominate the image classification and segmentation literature. Convolution on an image, in a nutshell, is the sum of neighboring pixels around a center pixel specified by a filter with parameterized size and learnable weight. The same concept is used in a spatial convolutional network, which aggregates the features of neighboring nodes into the center node.\n",
    "\n",
    "<img src=\"img/9_gnn.png\" title=\"Left: Convolution on a regular graph such as an image. Right: Convolution on the arbitrary graph structure. | Image: A Comprehensive Survey on Graph Neural Networks\" style=\"width: 500px;\" />\n",
    "\n",
    "##  Spectral Convolutional Networks\n",
    "\n",
    "Spectral convolution networks have a solid mathematical foundation when compared to other types of GNN. The spectral convolutional network is based on graph signal processing theory as well as graph convolution simplification and approximation. Graph convolution can be reduced to the following:\n",
    "\n",
    "$$g_{\\theta'}\\ast x \\approx \\sum_{k=0}^K \\theta_kT_k(\\Lambda)$$\n",
    "\n",
    "After further simplification Kipf and Welling suggest a two-layered neural network structure, described as:\n",
    "\n",
    "$$Z=f(X,A)=\\mathit{softmax}(\\hat{A}\\mathit{Relu}(\\hat{A}XW^{(0)})W^{(1)})$$\n",
    "\n",
    "$A_{head}$ is the pre-processed Laplacian of the original graph adjacency matrix $A$. This formula looks very familiar if you have some experience in machine learning because it’s nothing but two fully connected layer structures that programmers commonly use. Nevertheless, it serves as graph convolution in this case.\n",
    "\n",
    "### Spectral convolutional networks vs Spectral convolutional networks\n",
    "\n",
    "Despite having different starting points, spectral and spatial convolutional networks follow the same propagation rule. The format of all currently available convolutional graph neural networks is the same. They are all attempting to learn a function to pass node information around and update node state via this message-passing process. A message-passing neural network with \n",
    " - message-passing function: $M_t:m^{l+1}=M_t(H^l,A)$\n",
    " - node update function: $U_t:H^{l+1}=U_t(H^l,m^{l+1})$\n",
    " - readout function: $R_t: y=R(H^l)$\n",
    "\n",
    "can be expressed as any graph neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What GNN can do?\n",
    "\n",
    "GNN can solve in tasks:\n",
    "\n",
    "- Node classification\n",
    "- Link prediction\n",
    "- Graph classification\n",
    "\n",
    "### Node classification\n",
    "\n",
    "The goal of node classification is to predict the node embedding for each node in a graph. This type of problem is typically trained semi-supervised, with only a portion of the graph labeled. Citation networks, Reddit posts, YouTube videos, and Facebook friendships are examples of common node classification applications.\n",
    "\n",
    "### Link prediction\n",
    "\n",
    "The task of link prediction is to understand the relationship between entities in graphs and predict whether two entities are connected. A recommender system, for example, can be modeled as a link prediction problem. When we feed the model a collection of user reviews of various products, the task is to predict the users' preferences and tune the recommender system to push more relevant products based on the users' interests.\n",
    "\n",
    "### Graph classification\n",
    "\n",
    "The goal of graph classification is to divide the entire graph into different categories. It's similar to image classification, but the target is a graph. There are numerous industrial problems where graph classification can be used; for example, in chemistry, biomedicine, or physics, we can provide the model with a molecular structure and ask it to classify the target into meaningful categories. The model then speeds up the analysis of atoms, molecules, and other structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Applications\n",
    "\n",
    "### Natural Language Processing (NLP)\n",
    "\n",
    "GNN is frequently used in natural language processing (NLP), which is where GNN got its start. If you've worked with natural language processing (NLP), you're probably thinking that text is a type of sequential or temporal data that we can describe with a recurrent neural network (RNN) or a long short-term memory (LTSM). GNN, on the other hand, approaches the problem from an entirely different perspective. GNN predicts categories by utilizing the inner relationships of words or documents. A citation network, for example, attempts to predict each paper's label in a network based on the paper citation relationship and the words cited in other papers. GNN can also construct a syntactic model by examining different parts of sentences rather than only working sequentially as RNN or LTSM do.\n",
    "\n",
    "### Computer Vision\n",
    "\n",
    "Many GNN-based methods have achieved cutting-edge performance in image object detection, but we still don't know the relationships between the objects. Using graphs to model relationships between objects detected by a CNN-based detector is one successful application of GNN in computer vision (CV). After detecting objects in images, they are fed into a GNN inference for relationship prediction. The GNN inference produces a generated graph that models the relationships between various objects.\n",
    "\n",
    "<img src=\"img/16_gnn.png\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "Image generation from graph descriptions is another intriguing CV application. This is almost the inverse of the preceding application. Text-to-image generation using generative adversarial network (GAN) or autoencoder is the traditional method of image generation. Rather than using text to describe images, graph-to-image generation provides more information about the semantic structures of the images.\n",
    "\n",
    "<img src=\"img/17_gnn.png\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "The most intriguing application is zero-shot learning (ZSL), which learns to classify an object with no target class training samples. If no training samples are provided, the model must think in order to recognize a target. Assume we're given three images and told to find an okapi among them. We've never seen an okapi before, but if we're also told that an okapi is a deer-faced animal with four legs and zebra-striped skin, it's not difficult to figure out which one is an okapi. The detected features are typically converted into text to simulate this thought process. Text encodings, on the other hand, are independent of one another. The relationships between the text descriptions are difficult to model. Graph representations, on the other hand, accurately model these relationships and assist the machine in thinking more like a human.\n",
    "\n",
    "<img src=\"img/18_gnn.png\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "### Other applications\n",
    "\n",
    "Human behavior detection, traffic control, molecular structure study, recommender systems, program verification, logical reasoning, social influence prediction, and adversarial attack prevention are some of the more practical applications of GNN. Through social network analysis, for example, GNN can be used to cluster people into different community groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN in code\n",
    "\n",
    "Now we are implementing GNN using PyTorch and PyTorch Geometric (PyG), a Graph Neural Network framework built on top of PyTorch that runs blazingly fast. It is several times faster than the most well-known GNN framework, DGL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Geometric Basics (PyG basic)\n",
    "\n",
    "#### Data\n",
    "The *torch_geometric.data* module contains a Data class that allows you to create graphs from your data very easily. You only need to specify:\n",
    "\n",
    "1. the attributes/features associated with each node\n",
    "2. the connectivity/adjacency of each node (edge index)\n",
    "\n",
    "Let’s use the following graph to demonstrate how to create a Data object\n",
    "\n",
    "<img src=\"img/GNNEx01.PNG\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "There are 4 nodes in the graph, $A \\dots D$, each of which is associated with a 2-dimensional feature vector, and a label y indicating its class. These two can be represented as FloatTensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install PyG\n",
    "\n",
    "Please follow the link:[https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/alisa/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/alisa/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-1.10.0+cu102.html\n",
      "Requirement already satisfied: torch-scatter in /home/alisa/anaconda3/lib/python3.8/site-packages (2.1.0+pt113cpu)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/alisa/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/alisa/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/alisa/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/alisa/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu102.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph connectivity (edge index) should be confined with the COO format, i.e. the first list contains the index of the source nodes, while the index of target nodes is specified in the second list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 2, 0, 3],\n",
    "                           [1, 0, 1, 3, 2]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the order of the edge index is irrelevant to the Data object you create since such information is only for computing the adjacency matrix. Therefore, the above edge_index express the same information as the following one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 2, 1, 0, 3],\n",
    "                           [3, 1, 0, 1, 2]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, y=y, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset creation procedure is not very straightforward, but it may seem familiar to those who’ve used torchvision, as PyG is following its convention. PyG provides two different types of dataset classes, InMemoryDataset and Dataset. As they indicate literally, the former one is for data that fit in your RAM, while the second one is for much larger data. Since their implementations are quite similar, I will only cover InMemoryDataset.\n",
    "\n",
    "To create an InMemoryDataset object, there are 4 functions you need to implement:\n",
    "\n",
    "- *raw_file_names()*: It returns a list that shows a list of raw, unprocessed file names. If you only have a file then the returned list should only contain 1 element. In fact, you can simply return an empty list and specify your file later in *process()*.\n",
    "- *processed_file_names()*: It also returns a list containing the file names of all the processed data. After *process()* is called, Usually, the returned list should only have one element, storing the only processed data file name.\n",
    "- *download()*: This function should download the data you are working on to the directory as specified in self.raw_dir. If you don’t need to download data, simply drop in <code>pass</code> in the function.\n",
    "- *process()*: This is the most important method of Dataset. You need to gather your data into a list of Data objects. Then, call *self.collate()* to compute the slices that will be used by the DataLoader object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "The DataLoader class allows you to feed data by batch into the model effortlessly. To create a DataLoader object, you simply specify the Dataset and the batch size you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every iteration of a DataLoader object yields a Batch object, which is very much like a Data object but with an attribute, “batch”. It indicates which graph each node is associated with. Since a DataLoader aggregates x, y, and edge_index from different samples/ graphs into Batches, the GNN model needs this “batch” information to know which nodes belong to the same graph within a batch to perform computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessagePassing\n",
    "\n",
    "Message passing is the essence of GNN which describes how node embeddings are learned. I have talked about in my last post, so I will just briefly run through this with terms that conform to the PyG documentation.\n",
    "\n",
    "$$x_i^{(k)}= \\gamma^{(k)}(x_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)}\\phi^{(k)}(x_i^{(k-1)},x_j^{(k-1)},e_{i,j}))$$\n",
    "\n",
    "$x$ denotes the node embeddings, $e$ denotes the edge features, $\\phi$ denotes the message function, $\\square$ denotes the aggregation function, $\\gamma$ denotes the update function. If the edges in the graph have no feature other than connectivity, $e$ is essentially the edge index of the graph. The superscript represents the index of the layer. When $k=1$, $x$ represents the input feature of each node. Below I will illustrate how each function works:\n",
    "\n",
    "- <code>propagate(edge_index, size=None, **kwargs)</code>: It takes in edge index and other optional information, such as node features (embedding). Calling this function will consequently call message and update.\n",
    "- <code>message(**kwargs)</code>: You specify how you construct “message” for each of the node pair $(x_i, x_j)$. Since it follows the calls of propagate, it can take any argument passing to propagate. One thing to note is that you can define the mapping from arguments to the specific nodes with “_i” and “_j”. Therefore, you must be very careful when naming the argument of this function.\n",
    "- <code>update(aggr_out, **kwargs)</code>: It takes in the aggregated message and other arguments passed into propagate, assigning a new embedding value for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageConv\n",
    "\n",
    "Now, we implement [SageConv](https://arxiv.org/abs/1706.02216). The message passing formula of SageConv is defined as:\n",
    "\n",
    "$$h_{\\mathcal{N}(v)}^k \\leftarrow \\text{AGGREGATE}_k(\\{h_u^{k-1},\\forall u \\in \\mathcal{N}(v)\\})$$\n",
    "$$h_v^k \\leftarrow \\sigma(W^k \\cdot \\text{CONCAT}(h_v^{k-1},h_{\\mathcal{N}(v)}^k))$$\n",
    "\n",
    "Max pooling is used as the aggregation method. Therefore, the right-hand side of the first line can be written as:\n",
    "$$\\max(\\{\\sigma(W_{pool}h_{u_i}^k+b), \\forall u_i \\in \\mathcal{N}(v)\\}$$\n",
    "\n",
    "which illustrates how the “message” is constructed. Each neighboring node embedding is multiplied by a weight matrix, added a bias and passed through an activation function. \n",
    "\n",
    "As for the update part, the aggregated message and the current node embedding is aggregated. Then, it is multiplied by another weight matrix and applied another activation function.\n",
    "\n",
    "the SageConv layer class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "class SAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SAGEConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
    "        self.update_act = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        x_j = self.lin(x_j)\n",
    "        x_j = self.act(x_j)\n",
    "        \n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "\n",
    "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
    "        \n",
    "        new_embedding = self.update_lin(new_embedding)\n",
    "        new_embedding = self.update_act(new_embedding)\n",
    "        \n",
    "        return new_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example RecSys Challenge 2015\n",
    "\n",
    "The RecSys Challenge 2015 is challenging data scientists to build a session-based recommender system. Participants in this challenge are asked to solve two tasks:\n",
    "\n",
    "1. Predict whether there will be a buy event followed by a sequence of clicks\n",
    "2. Predict which item will be bought\n",
    "\n",
    "We can download the data from the official website of [RecSys Challenge 2015 and construct a Dataset in Kaggle](https://www.kaggle.com/datasets/chadgostopp/recsys-challenge-2015).\n",
    "\n",
    "The challenge provides two main sets of data, yoochoose-clicks.dat, and yoochoose-buys.dat, containing click events and buy events, respectively.\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "After downloading the data, we preprocess it so that it can be fed to our model. item_ids are categorically encoded to ensure the encoded item_ids, which will later be mapped to an embedding matrix, starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alisa/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3139: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>214536502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>214536500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>214536506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>214577561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07T13:56:37.614Z</td>\n",
       "      <td>214662742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp    item_id category\n",
       "0           1  2014-04-07T10:51:09.277Z  214536502        0\n",
       "1           1  2014-04-07T10:54:09.868Z  214536500        0\n",
       "2           1  2014-04-07T10:54:46.998Z  214536506        0\n",
       "3           1  2014-04-07T10:57:00.306Z  214577561        0\n",
       "4           2  2014-04-07T13:56:37.614Z  214662742        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./archive/yoochoose-clicks.dat', header=None)\n",
    "df.columns=['session_id','timestamp','item_id','category']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420374</td>\n",
       "      <td>2014-04-06T18:44:58.314Z</td>\n",
       "      <td>214537888</td>\n",
       "      <td>12462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>420374</td>\n",
       "      <td>2014-04-06T18:44:58.325Z</td>\n",
       "      <td>214537850</td>\n",
       "      <td>10471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281626</td>\n",
       "      <td>2014-04-06T09:40:13.032Z</td>\n",
       "      <td>214535653</td>\n",
       "      <td>1883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420368</td>\n",
       "      <td>2014-04-04T06:13:28.848Z</td>\n",
       "      <td>214530572</td>\n",
       "      <td>6073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>420368</td>\n",
       "      <td>2014-04-04T06:13:28.858Z</td>\n",
       "      <td>214835025</td>\n",
       "      <td>2617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp    item_id  price  quantity\n",
       "0      420374  2014-04-06T18:44:58.314Z  214537888  12462         1\n",
       "1      420374  2014-04-06T18:44:58.325Z  214537850  10471         1\n",
       "2      281626  2014-04-06T09:40:13.032Z  214535653   1883         1\n",
       "3      420368  2014-04-04T06:13:28.848Z  214530572   6073         1\n",
       "4      420368  2014-04-04T06:13:28.858Z  214835025   2617         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_df = pd.read_csv('./archive/yoochoose-buys.dat', header=None)\n",
    "buy_df.columns=['session_id','timestamp','item_id','price','quantity']\n",
    "\n",
    "buy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id     4431931\n",
       "timestamp     24590089\n",
       "item_id          48255\n",
       "category           331\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out item session with length < 2\n",
    "df['valid_session'] = df.session_id.map(df.groupby('session_id')['item_id'].size() > 2)\n",
    "df = df.loc[df.valid_session].drop('valid_session',axis=1)\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is quite large, we subsample it for easier demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    1000000\n",
       "timestamp     5557628\n",
       "item_id         37216\n",
       "category          257\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly sample a couple of them\n",
    "sampled_session_id = np.random.choice(df.session_id.unique(), 1000000, replace=False)\n",
    "df = df.loc[df.session_id.isin(sampled_session_id)]\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.559688"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average length of session \n",
    "df.groupby('session_id')['item_id'].size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>1612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>1611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>1613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>7173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01T20:52:12.357Z</td>\n",
       "      <td>5759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                 timestamp  item_id  category\n",
       "0            1  2014-04-07T10:51:09.277Z     1612         0\n",
       "1            1  2014-04-07T10:54:09.868Z     1611         0\n",
       "2            1  2014-04-07T10:54:46.998Z     1613         0\n",
       "3            1  2014-04-07T10:57:00.306Z     7173         0\n",
       "49          19  2014-04-01T20:52:12.357Z     5759         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "item_encoder = LabelEncoder()\n",
    "category_encoder = LabelEncoder()\n",
    "df['item_id'] = item_encoder.fit_transform(df.item_id )\n",
    "df['category']= category_encoder.fit_transform(df.category.apply(str))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420374</td>\n",
       "      <td>2014-04-06T18:44:58.314Z</td>\n",
       "      <td>1901</td>\n",
       "      <td>12462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>420374</td>\n",
       "      <td>2014-04-06T18:44:58.325Z</td>\n",
       "      <td>1893</td>\n",
       "      <td>10471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420368</td>\n",
       "      <td>2014-04-04T06:13:28.848Z</td>\n",
       "      <td>776</td>\n",
       "      <td>6073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>420368</td>\n",
       "      <td>2014-04-04T06:13:28.858Z</td>\n",
       "      <td>29347</td>\n",
       "      <td>2617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70427</td>\n",
       "      <td>2014-04-02T15:54:07.144Z</td>\n",
       "      <td>26493</td>\n",
       "      <td>3769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                 timestamp  item_id  price  quantity\n",
       "0       420374  2014-04-06T18:44:58.314Z     1901  12462         1\n",
       "1       420374  2014-04-06T18:44:58.325Z     1893  10471         1\n",
       "3       420368  2014-04-04T06:13:28.848Z      776   6073         1\n",
       "4       420368  2014-04-04T06:13:28.858Z    29347   2617         1\n",
       "26       70427  2014-04-02T15:54:07.144Z    26493   3769         1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_df = buy_df.loc[buy_df.session_id.isin(df.session_id)]\n",
    "buy_df['item_id'] = item_encoder.transform(buy_df.item_id)\n",
    "buy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{87: [12996, 31056, 22447, 27395, 26550, 27422, 26275],\n",
       " 189: [10178],\n",
       " 197: [24949],\n",
       " 277: [30016, 30017],\n",
       " 319: [9294, 9294],\n",
       " 484: [16786, 16786],\n",
       " 507: [21558, 6043],\n",
       " 593: [26726, 7935],\n",
       " 612: [23235],\n",
       " 651: [21394, 21394, 30613],\n",
       " 708: [8081, 16369],\n",
       " 873: [26492],\n",
       " 899: [19622],\n",
       " 966: [2924, 21418],\n",
       " 1112: [26267],\n",
       " 1372: [27326, 27329, 27327, 27328],\n",
       " 1457: [26722],\n",
       " 1562: [21599],\n",
       " 1713: [27455, 27429],\n",
       " 1834: [30766, 30996],\n",
       " 1962: [27458, 27455, 27429, 27467, 29279, 26734, 27457],\n",
       " 2071: [27378, 27322, 27441, 27330],\n",
       " 2101: [26402],\n",
       " 2103: [27422, 21517, 27406, 27408],\n",
       " 2256: [30766, 30994, 30996, 30995],\n",
       " 2377: [30766],\n",
       " 2409: [18174, 26483, 26496, 26482],\n",
       " 2426: [27464, 27469],\n",
       " 2553: [26720, 26768, 6522],\n",
       " 2666: [19404, 18795],\n",
       " 2834: [21687],\n",
       " 2859: [20098],\n",
       " 2998: [7935],\n",
       " 3074: [28911, 21030, 17360, 17360],\n",
       " 3191: [16785, 31206],\n",
       " 3264: [20099],\n",
       " 3456: [26351, 27416],\n",
       " 3474: [19635, 19635],\n",
       " 3517: [20943, 24949],\n",
       " 3624: [18528],\n",
       " 3811: [26722, 29279],\n",
       " 3841: [28911, 28911, 28911, 28911],\n",
       " 3852: [15993],\n",
       " 3929: [21281, 27415, 606],\n",
       " 3948: [26726, 26722, 26727],\n",
       " 3987: [17438],\n",
       " 4023: [10581, 10581],\n",
       " 4083: [29640],\n",
       " 4266: [26711],\n",
       " 4328: [23235, 23069],\n",
       " 4436: [1504],\n",
       " 4453: [23085],\n",
       " 4749: [26722, 26726],\n",
       " 4759: [26251, 26552],\n",
       " 4761: [26251, 26251],\n",
       " 4982: [15414, 16587],\n",
       " 5038: [4383, 7968],\n",
       " 5058: [9938],\n",
       " 5099: [21420, 21420],\n",
       " 5291: [26720, 16692],\n",
       " 5488: [17814],\n",
       " 5688: [917],\n",
       " 5927: [21397],\n",
       " 5984: [29921, 7365, 26492],\n",
       " 6013: [28871, 8289],\n",
       " 6141: [21414, 21414, 10129],\n",
       " 6343: [353],\n",
       " 6707: [21418, 21418],\n",
       " 6709: [23084, 6590, 26370, 26254],\n",
       " 6838: [20098],\n",
       " 6948: [16079],\n",
       " 7054: [27322],\n",
       " 7112: [27379, 26724],\n",
       " 7173: [26251],\n",
       " 7324: [10383, 10429, 1107],\n",
       " 7341: [8081],\n",
       " 7468: [26471, 26470, 22769],\n",
       " 7593: [26483, 1489],\n",
       " 7742: [8868],\n",
       " 7907: [21398, 21432],\n",
       " 7916: [26552, 22769],\n",
       " 8594: [27441, 27354],\n",
       " 8628: [478, 479],\n",
       " 8749: [1599],\n",
       " 8793: [27350, 21690],\n",
       " 8826: [30766],\n",
       " 8926: [27378, 27348],\n",
       " 9073: [27379, 26724, 10159],\n",
       " 9179: [21414],\n",
       " 9406: [27468, 2394],\n",
       " 9424: [26490, 30766],\n",
       " 9503: [11597, 19206],\n",
       " 9812: [1924],\n",
       " 10224: [31056],\n",
       " 10418: [26659],\n",
       " 10553: [26551, 27441, 27394, 27470],\n",
       " 10603: [23235, 27378, 23235, 27378],\n",
       " 10647: [11233, 11233],\n",
       " 10678: [11849, 7893],\n",
       " 10719: [9143],\n",
       " 10802: [9545],\n",
       " 10816: [26729, 26721, 27441, 27322],\n",
       " 10837: [21413, 21413],\n",
       " 10892: [27349],\n",
       " 11051: [21817, 2114, 21566],\n",
       " 11213: [3565, 9385, 26267],\n",
       " 11491: [31542, 31541, 31870, 32025],\n",
       " 11502: [18822],\n",
       " 11527: [21536],\n",
       " 11718: [27430, 27432, 23083],\n",
       " 11886: [1599, 27332, 27330, 27332],\n",
       " 11927: [1280],\n",
       " 12031: [429],\n",
       " 12062: [16196, 16249, 6193, 9725],\n",
       " 12184: [27350],\n",
       " 12242: [23067, 23235],\n",
       " 12421: [16786],\n",
       " 12593: [9362],\n",
       " 12714: [15993, 26761, 15993, 26761],\n",
       " 12874: [21401, 21392],\n",
       " 13007: [16785, 16737, 27348],\n",
       " 13204: [21598],\n",
       " 13313: [22666],\n",
       " 13477: [31594, 31602, 31602, 31594],\n",
       " 13506: [26482, 26482],\n",
       " 13653: [27330, 26731, 27332, 26723],\n",
       " 13726: [14734],\n",
       " 13741: [26711],\n",
       " 13779: [20050, 20050],\n",
       " 13836: [1573, 1573],\n",
       " 13879: [19128, 6108],\n",
       " 13883: [10677, 10677],\n",
       " 14542: [14497, 24949],\n",
       " 14626: [18079, 20939],\n",
       " 14676: [21395],\n",
       " 14726: [31284, 22769],\n",
       " 14884: [21586, 27328],\n",
       " 14982: [446],\n",
       " 15108: [23065, 23235],\n",
       " 15214: [26768, 26768],\n",
       " 15217: [1379, 27378, 6569],\n",
       " 15218: [21417],\n",
       " 15251: [27328, 27326, 26734],\n",
       " 15538: [19843, 16078],\n",
       " 15568: [27455, 29279, 27424, 27786],\n",
       " 15723: [32149, 26472],\n",
       " 15827: [32149, 19126, 21685],\n",
       " 15864: [79],\n",
       " 15872: [23066],\n",
       " 15952: [21395],\n",
       " 15961: [21392],\n",
       " 16224: [11824],\n",
       " 16712: [21413, 26763],\n",
       " 16721: [21748],\n",
       " 16748: [9195, 27738],\n",
       " 16861: [30314, 23235, 23071],\n",
       " 16939: [5593, 26552],\n",
       " 16963: [30492],\n",
       " 17144: [21398],\n",
       " 17363: [23236],\n",
       " 17614: [27458, 27457, 27455, 29279, 27429],\n",
       " 17802: [21393, 21393, 21393, 21419],\n",
       " 18094: [21393, 21393, 28912, 21419],\n",
       " 18133: [27382, 26727],\n",
       " 18713: [21419, 28912, 28910, 21419],\n",
       " 18714: [29365],\n",
       " 18742: [27422, 26760],\n",
       " 18744: [71],\n",
       " 18779: [8289, 21694],\n",
       " 18791: [21428, 21393, 21428],\n",
       " 18927: [21396],\n",
       " 18982: [9385, 9384],\n",
       " 19094: [10050, 19671, 10064],\n",
       " 19171: [7888],\n",
       " 19219: [27394, 27354],\n",
       " 19677: [27465],\n",
       " 19683: [26722, 26726],\n",
       " 19782: [27429, 29279, 27455, 7162],\n",
       " 19806: [8868],\n",
       " 19877: [1371],\n",
       " 20178: [27322, 26723],\n",
       " 20529: [19589],\n",
       " 20919: [13556, 13587, 15903, 13338, 15905],\n",
       " 20952: [27354],\n",
       " 21249: [26724, 27379],\n",
       " 21367: [18281],\n",
       " 21384: [11661],\n",
       " 21432: [27348, 27378, 27349],\n",
       " 21696: [27323, 26722, 27323, 26722],\n",
       " 21828: [26550, 26392, 26373, 26391, 26275, 21980, 25606],\n",
       " 21988: [21395],\n",
       " 21998: [19531],\n",
       " 22049: [18362],\n",
       " 22263: [15362],\n",
       " 22387: [21393],\n",
       " 22461: [9384, 9385, 1875],\n",
       " 22516: [27378, 27377, 26577, 26576],\n",
       " 22541: [26729],\n",
       " 22813: [29445, 29445],\n",
       " 22956: [27904],\n",
       " 22958: [27905],\n",
       " 22976: [2485],\n",
       " 23239: [30515],\n",
       " 23571: [20918, 26559],\n",
       " 24079: [27382],\n",
       " 24477: [21393, 21393, 21393, 21393],\n",
       " 24508: [26707, 27904],\n",
       " 24528: [19628, 29355, 27393],\n",
       " 24599: [30766, 20109],\n",
       " 24703: [27394, 27394],\n",
       " 24888: [7935],\n",
       " 24929: [21410, 21425],\n",
       " 25047: [27382, 27350, 27323],\n",
       " 25081: [26550, 26552, 26554],\n",
       " 25144: [9384],\n",
       " 25333: [3652],\n",
       " 25378: [5041, 23236],\n",
       " 25634: [26559],\n",
       " 25892: [417, 416],\n",
       " 25988: [29500],\n",
       " 26053: [2348, 2906, 8295, 4854, 24942],\n",
       " 26099: [26547, 27385],\n",
       " 26312: [21393, 21428],\n",
       " 26331: [28944],\n",
       " 26399: [27429, 27467, 27424, 27457, 27786, 27455, 30196],\n",
       " 26493: [21392],\n",
       " 26568: [21429],\n",
       " 26856: [21419],\n",
       " 26919: [21395, 21395],\n",
       " 27071: [9845, 26496, 26483],\n",
       " 27082: [7442],\n",
       " 27091: [9655, 9655],\n",
       " 27297: [31056],\n",
       " 27356: [26722, 26727],\n",
       " 27526: [31860],\n",
       " 27531: [30463, 29263, 15993],\n",
       " 27553: [28872, 21755, 27904],\n",
       " 27591: [1924],\n",
       " 27726: [27391, 20054, 27354],\n",
       " 27759: [27441, 27332],\n",
       " 27963: [23066],\n",
       " 27981: [30196, 22434],\n",
       " 28059: [18191],\n",
       " 28073: [21429, 21392],\n",
       " 28139: [26480],\n",
       " 28201: [19845, 19873],\n",
       " 28463: [27349, 27378],\n",
       " 28572: [28871],\n",
       " 28576: [21413, 21413],\n",
       " 28672: [26733, 26732],\n",
       " 28929: [26722, 26726, 26727],\n",
       " 28931: [26722, 26722],\n",
       " 29044: [6512],\n",
       " 29051: [11200],\n",
       " 29269: [26492],\n",
       " 29353: [21392],\n",
       " 29389: [26713, 26333, 23077],\n",
       " 29647: [27397, 27394],\n",
       " 29701: [19122, 19134],\n",
       " 29703: [27379, 26724],\n",
       " 29716: [22770],\n",
       " 29846: [17752],\n",
       " 29874: [30551],\n",
       " 29926: [21391],\n",
       " 29936: [32034, 16785, 16738, 32033, 32017, 31237, 31260],\n",
       " 29956: [26552, 26550],\n",
       " 30082: [22769, 26251],\n",
       " 30368: [26003, 26353, 3967, 12548],\n",
       " 30654: [11280],\n",
       " 30741: [30766, 30766],\n",
       " 30843: [2579],\n",
       " 31046: [31056, 31056],\n",
       " 31164: [21733, 7090],\n",
       " 31536: [17437, 17436, 18281],\n",
       " 31558: [14102],\n",
       " 31639: [21562, 27391],\n",
       " 31647: [21766, 11431],\n",
       " 31703: [21398, 21398],\n",
       " 31851: [26482],\n",
       " 31976: [27441],\n",
       " 32024: [26711, 27419],\n",
       " 32126: [30460],\n",
       " 32381: [7282],\n",
       " 32644: [7865],\n",
       " 32652: [6102, 4990],\n",
       " 32722: [27394, 31190],\n",
       " 32751: [2674],\n",
       " 32768: [9824],\n",
       " 32799: [8081, 8081],\n",
       " 32847: [1599, 1599],\n",
       " 33096: [22466],\n",
       " 33259: [31841, 16813, 16861, 31999, 31529, 32154, 27378],\n",
       " 33306: [27416, 2481],\n",
       " 33332: [8109],\n",
       " 33392: [1022],\n",
       " 33403: [26496, 26483],\n",
       " 33412: [26480, 26483, 26482, 26496],\n",
       " 33499: [26724, 27349, 26722],\n",
       " 33636: [7352],\n",
       " 33768: [27322, 27394],\n",
       " 33776: [27348, 27378, 26727],\n",
       " 33844: [26726, 27455, 29279, 27429, 27457],\n",
       " 33907: [4321, 11388],\n",
       " 34009: [16824, 31894, 31891, 16829],\n",
       " 34088: [16864, 21748],\n",
       " 34272: [26723, 7587, 27458],\n",
       " 34599: [1374, 264],\n",
       " 34696: [27323, 26560, 26490],\n",
       " 34964: [21748],\n",
       " 34991: [9195, 20850, 26399],\n",
       " 35011: [31029, 31028],\n",
       " 35396: [9384, 9385],\n",
       " 35737: [30788],\n",
       " 35789: [18860],\n",
       " 35858: [30766, 2354],\n",
       " 35973: [21417],\n",
       " 36433: [30766, 26724, 26727],\n",
       " 36538: [26391],\n",
       " 36581: [30860, 30861],\n",
       " 36583: [26472, 31029, 27332, 22790],\n",
       " 36716: [27385, 27441],\n",
       " 36797: [16800],\n",
       " 36882: [27441, 27354],\n",
       " 36941: [26724, 26722, 26724, 26722],\n",
       " 37077: [21391],\n",
       " 37113: [20959],\n",
       " 37217: [27394, 27332],\n",
       " 37279: [27468, 20943],\n",
       " 37324: [27322, 27394],\n",
       " 37437: [26391, 26555, 26705, 26550, 22769, 26552, 23084, 26554, 27328],\n",
       " 37593: [13923],\n",
       " 37652: [7935],\n",
       " 37879: [11653],\n",
       " 38008: [9852],\n",
       " 38163: [3652],\n",
       " 38191: [26570, 30766, 26570, 30766],\n",
       " 38242: [26273],\n",
       " 38248: [27323, 27378],\n",
       " 38603: [353],\n",
       " 38653: [26722],\n",
       " 38683: [27458, 27348, 26722, 26722, 27331, 27378, 27457],\n",
       " 38707: [7077],\n",
       " 38708: [10419],\n",
       " 38788: [13923, 1670],\n",
       " 38853: [28912],\n",
       " 38871: [13947],\n",
       " 38992: [26496],\n",
       " 39006: [27385, 27332, 31851, 27441, 16895],\n",
       " 39136: [27463, 31549],\n",
       " 39237: [26496, 8268],\n",
       " 39416: [1873, 12086],\n",
       " 39859: [28739],\n",
       " 39877: [22868, 16196],\n",
       " 39928: [21442],\n",
       " 39936: [26485, 26550, 27422],\n",
       " 40021: [26734, 26748],\n",
       " 40029: [6111, 27348, 9427],\n",
       " 40119: [28871],\n",
       " 40293: [27385, 27379, 26724],\n",
       " 40457: [26573, 20109],\n",
       " 40633: [26726, 26722, 27418],\n",
       " 40646: [14102],\n",
       " 40717: [29365],\n",
       " 40873: [26400],\n",
       " 40993: [27394, 27354, 27322, 27467],\n",
       " 41182: [23067],\n",
       " 41208: [9824],\n",
       " 41346: [15993],\n",
       " 41363: [26472, 32149, 17598, 17603],\n",
       " 41391: [28911, 21428],\n",
       " 41397: [2063,\n",
       "  26322,\n",
       "  5513,\n",
       "  26311,\n",
       "  27904,\n",
       "  28012,\n",
       "  7596,\n",
       "  21729,\n",
       "  7596,\n",
       "  2063,\n",
       "  26311,\n",
       "  26322,\n",
       "  27904,\n",
       "  5513,\n",
       "  28012,\n",
       "  21729],\n",
       " 41576: [26722, 27330, 27331],\n",
       " 41653: [5611, 5611],\n",
       " 41717: [21419, 28912, 21419, 28912],\n",
       " 41741: [27468],\n",
       " 41906: [21419],\n",
       " 41908: [10640, 3648, 3644],\n",
       " 42071: [30857, 30626],\n",
       " 42079: [27322, 27349, 7935, 21816, 27378],\n",
       " 42086: [27323, 26724, 27379],\n",
       " 42456: [26763, 26496],\n",
       " 42536: [27349, 27905],\n",
       " 42578: [28869],\n",
       " 42919: [21429],\n",
       " 43092: [27905, 4986],\n",
       " 43251: [26722, 26727],\n",
       " 43271: [26727, 26722],\n",
       " 43401: [23235, 22770, 23084, 27328, 26771],\n",
       " 43418: [27323, 26722, 27377, 27330, 26734, 26748, 19833],\n",
       " 43662: [26720, 27464],\n",
       " 43674: [26396],\n",
       " 43939: [28871],\n",
       " 43953: [21420],\n",
       " 43961: [9385],\n",
       " 44039: [13162],\n",
       " 44123: [21748],\n",
       " 44206: [21397],\n",
       " 44221: [19845],\n",
       " 44263: [26724, 26722],\n",
       " 44522: [8868],\n",
       " 44556: [780, 31016, 22466, 31016, 22466, 780],\n",
       " 44618: [20054],\n",
       " 44739: [2],\n",
       " 44774: [14101, 28859, 713],\n",
       " 44914: [9247, 22760],\n",
       " 45022: [31056],\n",
       " 45074: [3652],\n",
       " 45212: [1599, 7008],\n",
       " 45469: [3572, 21414],\n",
       " 45546: [20099, 27332],\n",
       " 45827: [30766, 30997, 30995],\n",
       " 45899: [19598],\n",
       " 46017: [31056],\n",
       " 46132: [27322, 4265],\n",
       " 46272: [26768, 27378],\n",
       " 46527: [30859, 31015, 31015, 30859],\n",
       " 46626: [22864, 19869, 15846],\n",
       " 46939: [26726],\n",
       " 47003: [26274],\n",
       " 47004: [23084, 27332, 27330],\n",
       " 47067: [30462],\n",
       " 47127: [17316],\n",
       " 47184: [29623, 29623],\n",
       " 47314: [26726, 26722, 26724],\n",
       " 47318: [9824],\n",
       " 47412: [6338],\n",
       " 47764: [26726, 26727],\n",
       " 47841: [21694],\n",
       " 48022: [27385, 16418],\n",
       " 48086: [26391, 26392, 26550],\n",
       " 48108: [21393, 21428],\n",
       " 48193: [349, 1810],\n",
       " 48243: [27382, 7935, 26559],\n",
       " 48298: [9385],\n",
       " 48309: [21748],\n",
       " 48391: [30201],\n",
       " 48448: [27391, 27378, 26659, 27469, 27415],\n",
       " 48663: [21428],\n",
       " 48994: [27395, 20902],\n",
       " 49043: [30766, 30995],\n",
       " 49103: [26398,\n",
       "  27331,\n",
       "  27326,\n",
       "  27326,\n",
       "  27325,\n",
       "  29279,\n",
       "  27328,\n",
       "  26705,\n",
       "  26395,\n",
       "  27327,\n",
       "  21302,\n",
       "  25608,\n",
       "  30196,\n",
       "  26713,\n",
       "  26552,\n",
       "  27786],\n",
       " 49236: [21419, 28871, 15840],\n",
       " 49259: [27458, 29279, 27455, 29279, 27455, 27429],\n",
       " 49407: [26651],\n",
       " 49483: [20098],\n",
       " 49734: [16786],\n",
       " 49751: [1021],\n",
       " 50219: [8869],\n",
       " 50252: [808],\n",
       " 50318: [19843],\n",
       " 50427: [27441],\n",
       " 50502: [32149, 14569],\n",
       " 50593: [21418, 28910],\n",
       " 50654: [9506],\n",
       " 50686: [18716],\n",
       " 50698: [30912, 30914],\n",
       " 50723: [8869],\n",
       " 51098: [28871, 28871],\n",
       " 51361: [27378, 27378, 27378, 27378],\n",
       " 51519: [9653, 7445, 21746, 4654],\n",
       " 51636: [22892],\n",
       " 51648: [21396],\n",
       " 51758: [26482, 26722],\n",
       " 51837: [3971, 3971],\n",
       " 51858: [11201, 27395, 26748, 27406],\n",
       " 51979: [27350],\n",
       " 52201: [26570, 8081],\n",
       " 52609: [26274],\n",
       " 52737: [26490, 26492, 26560],\n",
       " 52784: [9685, 26554, 26550],\n",
       " 52952: [18191],\n",
       " 52963: [8255],\n",
       " 52983: [23084, 26314, 26374],\n",
       " 53023: [23235, 23065, 23068],\n",
       " 53049: [18188],\n",
       " 53067: [27458, 27457, 29279, 27455],\n",
       " 53232: [26748],\n",
       " 53598: [15362],\n",
       " 53657: [31237, 31892],\n",
       " 53704: [26251],\n",
       " 53761: [26549, 18455],\n",
       " 53949: [19532, 26720],\n",
       " 53961: [23085],\n",
       " 53976: [26727, 26722],\n",
       " 54068: [31284],\n",
       " 54338: [26731, 27454, 30195, 27432, 30196, 27406, 27422],\n",
       " 54391: [18560],\n",
       " 54447: [3658],\n",
       " 54567: [27414, 30766],\n",
       " 54586: [27378, 27379],\n",
       " 54806: [26272, 26272],\n",
       " 54807: [26496],\n",
       " 54933: [19089, 17381],\n",
       " 54989: [15993, 26570],\n",
       " 55078: [26726],\n",
       " 55137: [1556],\n",
       " 55244: [19589, 21395],\n",
       " 55274: [7352],\n",
       " 55337: [21417],\n",
       " 55389: [19126, 26472],\n",
       " 55718: [29513],\n",
       " 55879: [21418, 21420],\n",
       " 55924: [21680, 26275],\n",
       " 56356: [26727],\n",
       " 56384: [29262],\n",
       " 56451: [31983, 16726],\n",
       " 56684: [2981],\n",
       " 56713: [21416, 21397],\n",
       " 56749: [21418, 21419],\n",
       " 56982: [29445, 29444],\n",
       " 56987: [9362, 8278],\n",
       " 57119: [26555],\n",
       " 57192: [26482],\n",
       " 57292: [30765],\n",
       " 57311: [21748],\n",
       " 57456: [27382],\n",
       " 57494: [30766, 30997],\n",
       " 57622: [32149, 16897, 27349, 9427],\n",
       " 57627: [30855, 30857],\n",
       " 57686: [27394],\n",
       " 57747: [9385, 9384],\n",
       " 57788: [3652],\n",
       " 57819: [8289, 14102],\n",
       " 58014: [16896, 16856],\n",
       " 58318: [9384],\n",
       " 58626: [26552, 26550],\n",
       " 58816: [28871],\n",
       " 58862: [27395, 26650, 26551, 27397],\n",
       " 58948: [26726, 26726],\n",
       " 58968: [19057, 7127, 26731, 27786],\n",
       " 59161: [19122],\n",
       " 59189: [7712],\n",
       " 59378: [1216],\n",
       " 59529: [21413, 21413],\n",
       " 59813: [23069, 30622, 707, 13657, 5749, 3503],\n",
       " 60351: [11200],\n",
       " 60357: [28944, 26496, 26483],\n",
       " 60678: [21396],\n",
       " 60887: [30622, 21711, 27381, 10673],\n",
       " 61026: [26766, 8295, 24942],\n",
       " 61134: [16018, 3682, 16017, 28750, 15926],\n",
       " 61739: [6746],\n",
       " 62056: [31056],\n",
       " 62213: [26724, 26722, 31523],\n",
       " 62317: [3652],\n",
       " 62392: [30996, 30994, 30994, 30996],\n",
       " 62519: [7206],\n",
       " 62528: [28910],\n",
       " 62589: [27366],\n",
       " 62949: [21729, 21729],\n",
       " 62984: [20050],\n",
       " 63027: [10372],\n",
       " 63074: [27354, 27354],\n",
       " 63152: [21413],\n",
       " 63176: [21397, 26734, 3565],\n",
       " 63311: [16773, 16785, 16726, 31956, 16767],\n",
       " 63792: [6648, 985, 29710, 26651, 2906, 27918, 10116, 2904],\n",
       " 63858: [15847],\n",
       " 64002: [26482],\n",
       " 64108: [1924],\n",
       " 64188: [14330],\n",
       " 64197: [26472, 26722],\n",
       " 64211: [15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023,\n",
       "  15023],\n",
       " 64253: [26306, 27378],\n",
       " 64426: [27419, 27331],\n",
       " 64554: [12417],\n",
       " 64682: [18455, 18456],\n",
       " 64714: [22432, 26391],\n",
       " 64759: [31184],\n",
       " 64802: [21536],\n",
       " 64972: [21817, 16293, 21813],\n",
       " 65144: [26722, 7936, 26724],\n",
       " 65172: [21414],\n",
       " 65192: [17349],\n",
       " 65202: [21418],\n",
       " 65207: [9384, 9385],\n",
       " 65242: [21392, 21392],\n",
       " 65304: [18196],\n",
       " 65337: [7935, 27471],\n",
       " 65473: [28872, 21755],\n",
       " 65494: [4023, 3614, 16056, 21085],\n",
       " 65863: [21395, 21395, 21394],\n",
       " 65874: [28871],\n",
       " 65954: [18581],\n",
       " 66006: [28910, 21419],\n",
       " 66293: [11202, 11202],\n",
       " 66833: [29615, 29754],\n",
       " 66976: [26758],\n",
       " 67012: [31184],\n",
       " 67048: [21413, 21393],\n",
       " 67133: [31603, 31869],\n",
       " 67509: [20108],\n",
       " 68052: [27441, 27332, 26486],\n",
       " 68137: [30766],\n",
       " 68271: [30766],\n",
       " 68353: [12996],\n",
       " 68378: [914, 21984],\n",
       " 68523: [27917],\n",
       " 68537: [431],\n",
       " 68663: [19134, 31541, 31237, 16843],\n",
       " 68796: [31472],\n",
       " 68952: [28871],\n",
       " 69044: [26374, 20059],\n",
       " 69166: [7533, 21761],\n",
       " 69267: [19141],\n",
       " 69316: [27408, 26705],\n",
       " 69416: [26724, 27379],\n",
       " 69466: [23234, 23235, 23069],\n",
       " 69514: [1924, 26650],\n",
       " 69659: [9248],\n",
       " 69692: [16785, 16738, 16759],\n",
       " 69772: [26722, 26722],\n",
       " 70061: [16785, 27322, 13942],\n",
       " 70084: [7352, 20929],\n",
       " 70252: [18782, 28, 28824],\n",
       " 70353: [30177],\n",
       " 70427: [26493],\n",
       " 70464: [26482, 31028],\n",
       " 70728: [10185],\n",
       " 70929: [30766],\n",
       " 70931: [27414, 19066],\n",
       " 71198: [26392, 17634],\n",
       " 71202: [26485, 26398],\n",
       " 71881: [21728, 18793, 7566, 21308, 9790, 5672, 14102, 21457, 9770, 6403],\n",
       " 72043: [23084, 8386, 8391],\n",
       " 72103: [8872, 26570],\n",
       " 72106: [29938],\n",
       " 72194: [22769, 26552, 26552, 22769, 22769, 26552, 26552, 22769],\n",
       " 72303: [1021],\n",
       " 72638: [26722],\n",
       " 72791: [21392],\n",
       " 73196: [27419, 27419],\n",
       " 73271: [21428, 21428, 21429],\n",
       " 73323: [26735, 26734],\n",
       " 73362: [23236, 23085],\n",
       " 73389: [21462, 7894],\n",
       " 73447: [26711],\n",
       " 73606: [22438, 11541, 11527],\n",
       " 73644: [21418],\n",
       " 73683: [20050, 26715],\n",
       " 73719: [31999, 31594, 31602],\n",
       " 74044: [23085],\n",
       " 74062: [671, 32010],\n",
       " 74101: [9504, 30445],\n",
       " 74207: [30454],\n",
       " 74518: [26723],\n",
       " 74531: [1021, 26722],\n",
       " 74539: [21428, 22438, 26496],\n",
       " 74622: [27441, 27331, 10128, 27354, 20918],\n",
       " 74708: [27441, 27332],\n",
       " 74741: [32149, 26485],\n",
       " 75254: [31056, 19126],\n",
       " 75282: [31056, 31056],\n",
       " 75334: [21396, 9991],\n",
       " 75376: [26711],\n",
       " 75447: [26761],\n",
       " 75497: [8868],\n",
       " 75561: [31477],\n",
       " 75598: [26391, 26251],\n",
       " 75599: [26391, 26251],\n",
       " 75698: [30458],\n",
       " 75814: [21657],\n",
       " 76012: [32011],\n",
       " 76018: [7935],\n",
       " 76278: [347],\n",
       " 76287: [29279, 27458],\n",
       " 76289: [1924, 21419],\n",
       " 76301: [26391],\n",
       " 76317: [21816, 27430],\n",
       " 76329: [21428, 21428],\n",
       " 76388: [27350, 27331, 27330, 11396],\n",
       " 76704: [26715, 4142],\n",
       " 76787: [21816],\n",
       " 76794: [28911, 28911, 21392, 21392],\n",
       " 76902: [30766, 21562, 26316],\n",
       " 76934: [1924, 28837, 31254, 16848, 32010, 32007, 32017],\n",
       " 77024: [21629, 21629],\n",
       " 77111: [22571, 429],\n",
       " 77168: [27394, 27394],\n",
       " 77262: [6111],\n",
       " 77532: [26722, 26722],\n",
       " 77619: [6590, 22790, 22790, 6590],\n",
       " 77632: [353],\n",
       " 77657: [21429],\n",
       " 77666: [1433, 1433],\n",
       " 77741: [19552, 28014],\n",
       " 77872: [31184],\n",
       " 77879: [21419, 28910],\n",
       " 77956: [26768],\n",
       " 78169: [9384],\n",
       " 78272: [31029, 31027],\n",
       " 78361: [4522],\n",
       " 78592: [9362],\n",
       " 78628: [6666],\n",
       " 79101: [3118, 26492],\n",
       " 79268: [30196],\n",
       " 79421: [21429],\n",
       " 79738: [26299],\n",
       " 79739: [26373, 26333, 26713, 26771],\n",
       " 79836: [21330, 21329],\n",
       " 79877: [21418, 21419],\n",
       " 80029: [16714, 27918],\n",
       " 80762: [21753],\n",
       " 80904: [19134, 26711, 19122],\n",
       " 80993: [29615, 29767, 29615, 29767],\n",
       " 81069: [26384, 11436, 26384, 11436, 26384, 26384],\n",
       " 81229: [27323],\n",
       " 81292: [21418],\n",
       " 81359: [26726],\n",
       " 81527: [26722, 26724, 26726],\n",
       " 81709: [27332, 22347, 26723],\n",
       " 81819: [27323, 27348, 26722],\n",
       " 82079: [8444],\n",
       " 82206: [18397],\n",
       " 82252: [19122],\n",
       " 82254: [3704, 985],\n",
       " 82431: [2165, 13652],\n",
       " 82451: [19532],\n",
       " 82548: [465, 466],\n",
       " 82554: [9384],\n",
       " 82692: [601, 601],\n",
       " 82756: [27350, 27323, 27382, 21419, 21419, 6335],\n",
       " 82774: [29548],\n",
       " 82886: [27378, 27378],\n",
       " 82993: [7206],\n",
       " 83216: [19134, 19134],\n",
       " 83258: [31184],\n",
       " 83263: [9385, 9384, 16708],\n",
       " 83309: [22863, 27349, 27354, 27350, 13942],\n",
       " 83322: [28869, 22458, 7006, 19532],\n",
       " 83348: [21694],\n",
       " 83572: [26485, 26463],\n",
       " 83842: [31029],\n",
       " 83881: [21428, 4982, 19534, 22667, 20901],\n",
       " 83992: [27323, 26570, 3651],\n",
       " 84008: [681, 30914, 11007, 714, 672, 700, 14834, 20253, 11008, 692],\n",
       " 84198: [4014],\n",
       " 84224: [3658],\n",
       " 84639: [30766],\n",
       " 84807: [17752],\n",
       " 85013: [7875],\n",
       " 85031: [19263],\n",
       " 85192: [14102],\n",
       " 85323: [11624],\n",
       " 85497: [21755],\n",
       " 85543: [19134],\n",
       " 85596: [31377],\n",
       " 85678: [27455, 29279, 27786, 27458],\n",
       " 85934: [21397, 21416, 21393, 21416],\n",
       " 85939: [28910],\n",
       " 86042: [26722],\n",
       " 86053: [429],\n",
       " 86149: [16293],\n",
       " 86237: [27394, 27354],\n",
       " 86238: [26554, 26251],\n",
       " 86244: [9670],\n",
       " 86403: [25605, 26750],\n",
       " 86583: [27378, 27323, 7935],\n",
       " 86673: [8268],\n",
       " 87131: [30766, 30766],\n",
       " 87266: [21729, 21729],\n",
       " 87347: [6777],\n",
       " 87361: [15993],\n",
       " 87404: [347],\n",
       " 87462: [28871, 27904, 26707],\n",
       " 87901: [27441, 27332, 27322, 21816],\n",
       " 87988: [21394],\n",
       " 88049: [30997, 30766, 30995, 30994],\n",
       " 88091: [23084, 27432, 27432, 27430, 27431],\n",
       " 88244: [10282],\n",
       " 88649: [26496, 5872],\n",
       " 88687: [27904, 27904, 26707],\n",
       " 88924: [26724, 27379],\n",
       " 88957: [21503, 21503, 22881, 22769],\n",
       " 88974: [2933],\n",
       " 89012: [10349],\n",
       " 89042: [5684, 9384, 9384, 5684],\n",
       " 89377: [27377, 2637],\n",
       " 89476: [23066, 23070, 23236],\n",
       " 89563: [627, 627],\n",
       " 89566: [12820],\n",
       " 89728: [26733, 15853, 15853, 26733],\n",
       " 89924: [27465, 3807],\n",
       " 90043: [8860],\n",
       " 90243: [21748],\n",
       " 90254: [26713, 30195, 27322],\n",
       " 90413: [21418],\n",
       " 90551: [26726],\n",
       " 90571: [27414],\n",
       " 90637: [9425],\n",
       " 90757: [5256],\n",
       " 90897: [26559, 7935],\n",
       " 90901: [26384, 31029, 31029],\n",
       " 90937: [16678, 16678],\n",
       " 91038: [26707],\n",
       " 91051: [27918, 26723, 26720, 19262, 27378],\n",
       " 91118: [21430],\n",
       " 91614: [18581],\n",
       " 91836: [3223, 4080],\n",
       " 91844: [27354],\n",
       " 91878: [18581],\n",
       " 91986: [23069],\n",
       " 92224: [446],\n",
       " 92574: [14393],\n",
       " 93142: [26727, 26726],\n",
       " 93199: [26763, 26763],\n",
       " 93241: [21694, 26322],\n",
       " 93282: [30912,\n",
       "  10973,\n",
       "  10969,\n",
       "  707,\n",
       "  8468,\n",
       "  8874,\n",
       "  13657,\n",
       "  13663,\n",
       "  10976,\n",
       "  8888,\n",
       "  13664,\n",
       "  8907,\n",
       "  13849,\n",
       "  3502,\n",
       "  3518,\n",
       "  3503],\n",
       " 93286: [26322, 26550, 26250],\n",
       " 93373: [15842],\n",
       " 93396: [301],\n",
       " 93428: [21396],\n",
       " 93443: [427],\n",
       " 93444: [28387, 21396],\n",
       " 93532: [30463],\n",
       " 93818: [21748, 26650, 26576, 26575],\n",
       " 93823: [28871],\n",
       " 93991: [21420],\n",
       " 94148: [24939],\n",
       " 94179: [20098],\n",
       " 94207: [27414, 28016, 27391],\n",
       " 94362: [30139, 27390],\n",
       " 94388: [27917],\n",
       " 94636: [9425, 21428],\n",
       " 94654: [22457, 20059, 26400, 21736],\n",
       " 94771: [26722, 26724],\n",
       " 94956: [16786, 16767],\n",
       " 94988: [27379,\n",
       "  27378,\n",
       "  26724,\n",
       "  26721,\n",
       "  27379,\n",
       "  26724,\n",
       "  27378,\n",
       "  26721,\n",
       "  27379,\n",
       "  26721,\n",
       "  27378,\n",
       "  26724],\n",
       " 95091: [21430],\n",
       " 95391: [21430],\n",
       " 96161: [23235, 23065],\n",
       " 96167: [4265],\n",
       " 96254: [27904],\n",
       " 96269: [21419, 429, 22571, 21419],\n",
       " 96297: [21395],\n",
       " 96303: [10581, 27379, 26575, 28014],\n",
       " 96468: [17777, 7987],\n",
       " 96514: [21394],\n",
       " 96536: [11695],\n",
       " 96562: [26733, 1150],\n",
       " 96563: [9425],\n",
       " 96576: [23067],\n",
       " 96578: [7888],\n",
       " 96606: [19839, 11823],\n",
       " 96707: [1375],\n",
       " 96764: [21751],\n",
       " 97012: [27391, 27415],\n",
       " 97246: [21416],\n",
       " 97272: [23084],\n",
       " 97321: [26761],\n",
       " 97344: [29378],\n",
       " 97371: [26729, 30765],\n",
       " 97396: [20109, 6111, 26703],\n",
       " 97449: [362, 13656],\n",
       " 97471: [26711, 19122],\n",
       " 97489: [30502],\n",
       " 97532: [26003, 19559],\n",
       " 97708: [27348, 26560, 8048],\n",
       " 97756: [19532, 26469],\n",
       " 97893: [29500, 5719],\n",
       " 98104: [28910, 28912, 21426, 28912],\n",
       " 98221: [26251, 26555, 26555],\n",
       " 98271: [26651, 26651],\n",
       " 98507: [21392],\n",
       " 98546: [26660],\n",
       " 98616: [18650],\n",
       " 98687: [17633],\n",
       " 98694: [16786, 26760],\n",
       " 98713: [26760],\n",
       " 98806: [9384, 9384, 9384],\n",
       " 98818: [21399],\n",
       " 98868: [20862],\n",
       " 98998: [21986],\n",
       " 99056: [11470, 18047, 26483, 26496, 21395],\n",
       " 99244: [21694, 21694],\n",
       " 99268: [28944, 16188, 28944, 16188],\n",
       " 99274: [31056],\n",
       " 99311: [677],\n",
       " 99391: [30914, 2991, 667, 21704],\n",
       " 99758: [27414, 27416],\n",
       " 99932: [23069, 23235],\n",
       " 100053: [7935],\n",
       " 100098: [4976],\n",
       " 100138: [27469, 26715, 14347],\n",
       " 100204: [26391, 23084, 9441, 26392],\n",
       " 100386: [8289, 8289, 21755],\n",
       " 100527: [25311, 27325, 21980, 26731],\n",
       " 100528: [3596, 22168, 89, 1669],\n",
       " 100594: [353],\n",
       " 100959: [27326, 27325, 23237],\n",
       " 101069: [20884, 20112],\n",
       " 101154: [31532, 16835],\n",
       " 101201: [27904, 27904],\n",
       " 101303: [27350],\n",
       " 101316: [21413],\n",
       " 101384: [19564],\n",
       " 101544: [21751, 21751],\n",
       " 102029: [26722, 27378],\n",
       " 102171: [21398, 21399, 15373, 30611],\n",
       " 102183: [27394, 26485, 13942],\n",
       " 102196: [26759],\n",
       " 102218: [8868],\n",
       " 102231: [19134],\n",
       " 102314: [31056, 31056],\n",
       " 102372: [26549, 26722, 26549, 26722],\n",
       " 102377: [26489],\n",
       " 102514: [32149],\n",
       " 102534: [26556, 22769, 15990, 26251, 26251, 26555, 28872, 27322],\n",
       " 102741: [15993],\n",
       " 102773: [16785, 16759],\n",
       " 102824: [31254, 31898, 26729, 31864],\n",
       " 102847: [26750, 26752],\n",
       " 103064: [26735, 26733],\n",
       " 103204: [27378, 27378],\n",
       " 103292: [19532, 29500, 20162, 19535],\n",
       " 103423: [9598],\n",
       " 103587: [23068, 23236],\n",
       " 103833: [21430],\n",
       " 103837: [2904, 27418, 27323],\n",
       " 103956: [31826, 31226, 31210],\n",
       " 103972: [27350],\n",
       " 103992: [26722],\n",
       " 104102: [26392],\n",
       " 104194: [27394, 27322],\n",
       " 104239: [21392],\n",
       " 104257: [30859, 30625],\n",
       " 104347: [6193],\n",
       " 104371: [21393],\n",
       " 104469: [18898, 16462, 26766, 15414],\n",
       " 104483: [26722, 26727, 27378],\n",
       " 104539: [30766],\n",
       " 104723: [26551, 26707, 26705],\n",
       " 104933: [22769, 25606, 26550, 26552, 23063],\n",
       " 105009: [9835],\n",
       " 105014: [20918, 26767],\n",
       " 105099: [23065],\n",
       " 105428: [26496],\n",
       " 105448: [19126],\n",
       " 105478: [1152, 8081, 31967, 31990, 31835],\n",
       " 105521: [21415, 21394],\n",
       " 105578: [26726],\n",
       " 105842: [27350, 27323, 27786, 27382, 19833, 20057, 30196],\n",
       " 105892: [1901, 30825],\n",
       " 105947: [15993],\n",
       " 106237: [30766, 27354],\n",
       " 106391: [14039],\n",
       " 106451: [27786, 19843],\n",
       " 106573: [30766, 27349],\n",
       " 106584: [30766, 527, 17881],\n",
       " 106713: [396, 1636, 7370, 1900, 7370, 396, 1900, 1636],\n",
       " 106861: [26496, 7893],\n",
       " 106907: [29279, 27457, 27429, 27458, 27455, 20918],\n",
       " 106958: [27382, 2475],\n",
       " 107069: [8268],\n",
       " 107073: [27441, 31026, 27332, 26391],\n",
       " 107149: [14956],\n",
       " 107192: [21428],\n",
       " 107212: [21415],\n",
       " 107292: [26722, 26724, 26484],\n",
       " 107342: [27349],\n",
       " 107429: [27328, 27326, 27329],\n",
       " 107464: [26713],\n",
       " 107497: [27350, 27441, 27332],\n",
       " 107523: [11436, 26486],\n",
       " 107761: [26549, 1130],\n",
       " 107771: [21424, 21424],\n",
       " 108059: [4976, 7925],\n",
       " 108266: [27415],\n",
       " 108301: [21425, 21414, 21414, 21425],\n",
       " 108522: [27415, 27354, 27391],\n",
       " 108553: [27350, 26727, 27378],\n",
       " 108611: [21330, 21329],\n",
       " 108662: [21462, 21462],\n",
       " 108691: [9362],\n",
       " 108703: [9655, 9362],\n",
       " 108714: [423],\n",
       " 108756: [15993],\n",
       " 108929: [21418, 21418],\n",
       " 109136: [27379],\n",
       " 109316: [10742],\n",
       " 109403: [8081, 26735, 26733, 27459, 2904],\n",
       " 109442: [28869],\n",
       " 109541: [21397],\n",
       " 109654: [10228],\n",
       " 109664: [1595],\n",
       " 110187: [27416, 27441, 27441, 27416],\n",
       " 110499: [26556],\n",
       " 110716: [23061],\n",
       " 110761: [18824],\n",
       " 111002: [7935],\n",
       " 111087: [28871, 21748, 20864],\n",
       " 111092: [19910],\n",
       " 111304: [26709, 28871],\n",
       " 111337: [6055],\n",
       " 111379: [26709, 28872],\n",
       " 111569: [19179, 3645, 26700],\n",
       " 111673: [301],\n",
       " 111796: [22770, 26551],\n",
       " 111829: [8616],\n",
       " 111848: [21428],\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_item_dict = dict(buy_df.groupby('session_id')['item_id'].apply(list))\n",
    "buy_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>1612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>1611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>1613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>7173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01T20:52:12.357Z</td>\n",
       "      <td>5759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                 timestamp  item_id  category\n",
       "0            1  2014-04-07T10:51:09.277Z     1612         0\n",
       "1            1  2014-04-07T10:54:09.868Z     1611         0\n",
       "2            1  2014-04-07T10:54:46.998Z     1613         0\n",
       "3            1  2014-04-07T10:57:00.306Z     7173         0\n",
       "49          19  2014-04-01T20:52:12.357Z     5759         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the ground truth, i.e. whether there is any buy event for a given session, we simply check if a session_id in yoochoose-clicks.dat presents in yoochoose-buys.dat as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>1612</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>1611</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>1613</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>7173</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01T20:52:12.357Z</td>\n",
       "      <td>5759</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                 timestamp  item_id  category  label\n",
       "0            1  2014-04-07T10:51:09.277Z     1612         0  False\n",
       "1            1  2014-04-07T10:54:09.868Z     1611         0  False\n",
       "2            1  2014-04-07T10:54:46.998Z     1613         0  False\n",
       "3            1  2014-04-07T10:57:00.306Z     7173         0  False\n",
       "49          19  2014-04-01T20:52:12.357Z     5759         0  False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.session_id.isin(buy_df.session_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Construction\n",
    "\n",
    "The data is ready to be transformed into a Dataset object after the preprocessing step. Here, we treat each item in a session as a node, and therefore all items in the same session form a graph. To build the dataset, we group the preprocessed data by session_id and iterate over these groups. In each iteration, the item_id in each group are categorically encoded again since for each graph, the node index should count from 0. Thus, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class YooChooseDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(YooChooseDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['../archive/yoochoose_click_binary_100000_sess.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "\n",
    "        # process by session_id\n",
    "        grouped = df.groupby('session_id')\n",
    "        for session_id, group in tqdm(grouped):\n",
    "            le = LabelEncoder()\n",
    "            sess_item_id = le.fit_transform(group.item_id)\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id','category']].sort_values('sess_item_id')[['item_id','category']].drop_duplicates().values\n",
    "\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "            edge_index = torch.tensor([source_nodes,\n",
    "                                   target_nodes], dtype=torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            if session_id in buy_item_dict:\n",
    "                positive_indices = le.transform(buy_item_dict[session_id])\n",
    "                label = np.zeros(len(node_features))\n",
    "                label[positive_indices] = 1\n",
    "            else:\n",
    "                label = [0] * len(node_features)\n",
    "\n",
    "\n",
    "            y = torch.FloatTensor(label)\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "            data_list.append(data)\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YooChooseDataset('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 100000, 100000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "one_tenth_length = int(len(dataset) * 0.1)\n",
    "train_dataset = dataset[:one_tenth_length * 8]\n",
    "val_dataset = dataset[one_tenth_length*8:one_tenth_length * 9]\n",
    "test_dataset = dataset[one_tenth_length*9:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alisa/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37216, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = df.item_id.max() +1\n",
    "num_categories = df.category.max()+1\n",
    "num_items , num_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv, SAGEConv, SGConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = GraphConv(embed_dim * 2, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.9)\n",
    "        self.conv2 = GraphConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.9)\n",
    "        self.conv3 = GraphConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.9)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=num_items, embedding_dim=embed_dim)\n",
    "        self.category_embedding = torch.nn.Embedding(num_embeddings=num_categories, embedding_dim=embed_dim)        \n",
    "        self.lin1 = torch.nn.Linear(256, 256)\n",
    "        self.lin2 = torch.nn.Linear(256, 128)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()        \n",
    "  \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        item_id = x[:,:,0]\n",
    "        category = x[:,:,1]\n",
    "        \n",
    "\n",
    "        emb_item = self.item_embedding(item_id).squeeze(1)\n",
    "        emb_category = self.category_embedding(category).squeeze(1)\n",
    "        \n",
    "#         emb_item = emb_item.squeeze(1)\n",
    "#         emb_cat\n",
    "        x = torch.cat([emb_item, emb_category], dim=1)  \n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "#                 print(x.shape)\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "     \n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.act2(x)      \n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(x.size(0)):\n",
    "            output = torch.matmul(emb_item[data.batch == i], x[i,:])\n",
    "\n",
    "            outputs.append(output)\n",
    "              \n",
    "        x = torch.cat(outputs, dim=0)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "crit = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Training our custom GNN is very easy, we simply iterate the DataLoader constructed from the training set and back-propagate the loss function. Here, we use Adam as the optimizer with the learning rate set to 0.005 and Binary Cross Entropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        label = data.y.to(device)\n",
    "        loss = crit(output, label)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation\n",
    "\n",
    "This label is highly unbalanced with an overwhelming amount of negative labels since most of the sessions are not followed by any buy event. In other words, a dumb model guessing all negatives would give you above 90% accuracy. Therefore, instead of accuracy, Area Under Curve (AUC) is a better metric for this task as it only cares if the positive examples are scored higher than the negative examples. We use the off-the-shelf AUC calculation function from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            pred = model(data).detach().cpu().numpy()\n",
    "\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "    predictions = np.hstack(predictions)\n",
    "    labels = np.hstack(labels)\n",
    "    \n",
    "    return roc_auc_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "Trained the model for 2 epoch, and measure the training, validation, and testing AUC scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Encountered invalid 'dim_size' (got '2372' but expected >= '4294967297')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m      3\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m evaluate(train_loader)\n\u001b[1;32m      4\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m evaluate(val_loader)    \n",
      "Cell \u001b[0;32mIn [24], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m crit(output, label)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [22], line 38\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([emb_item, emb_category], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#         print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#                 print(x.shape)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         x, edge_index, _, batch, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x, edge_index, \u001b[38;5;28;01mNone\u001b[39;00m, batch)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/graph_conv.py:79\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     76\u001b[0m     x: OptPairTensor \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_rel(out)\n\u001b[1;32m     83\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:454\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m         aggr_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 454\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    457\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:578\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    566\u001b[0m               ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    567\u001b[0m               dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch_geometric/nn/aggr/base.py:127\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()):\n\u001b[0;32m--> 127\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered invalid \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m                              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m                              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x, index, ptr, dim_size, dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Encountered invalid 'dim_size' (got '2372' but expected >= '4294967297')"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    loss = train()\n",
    "    train_acc = evaluate(train_loader)\n",
    "    val_acc = evaluate(val_loader)    \n",
    "    test_acc = evaluate(test_loader)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
    "          format(epoch, loss, train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Dr. Matt, please decide :-)\n",
    "\n",
    "Maybe we can try this: [pdf](https://arxiv.org/pdf/2206.00272.pdf) [Vision GNN](https://github.com/huawei-noah/Efficient-AI-Backbones) and [model](https://gitee.com/mindspore/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
